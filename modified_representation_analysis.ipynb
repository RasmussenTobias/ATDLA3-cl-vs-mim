{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "551a23c2",
      "metadata": {
        "id": "551a23c2"
      },
      "source": [
        "# Representation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1df8817",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1df8817",
        "outputId": "4dcab0f4-a785-45b6-a53f-823f5d39681d"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "#@markdown Execute this cell to import third-party software into the Colab environment.\n",
        "\n",
        "# check whether it runs in Colab\n",
        "root = \".\"\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Running in Colab.\")\n",
        "    !pip3 install timm==0.5.4\n",
        "    !pip3 install matplotlib==3.7.1\n",
        "    !pip3 install scikit-learn==1.2.2\n",
        "    !pip3 install fastai==2.7.12\n",
        "    !pip3 install einops==0.6.0\n",
        "    !pip3 install gdown==4.7.1\n",
        "    !pip3 install yacs==0.1.8    \n",
        "    !git clone https://github.com/naver-ai/cl-vs-mim.git\n",
        "    root = \"./cl-vs-mim\"\n",
        "    %cd $root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4df9c44",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4df9c44",
        "outputId": "ac4f49bc-05b1-45d0-ab48-da055b89017e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "#@markdown Execute this cell to check the Colab environment, including GPU availability.\n",
        "\n",
        "# check gpu env\n",
        "print(f\"Torch: {torch.__version__} \\n\" + \n",
        "      f\"Availability: {torch.cuda.is_available()}\")\n",
        "assert torch.cuda.is_available() == True, \"The GPU is turned off. To turn it on, navigate to: Runtime > Change Runtime Type.\"\n",
        "print(f\"Number: {torch.cuda.device_count()} \\n\" +\n",
        "      f\"Current device: {torch.cuda.current_device()} \\n\" +\n",
        "      f\"First device: {torch.cuda.device(0)} \\n\" +\n",
        "      f\"Device name: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001c712b",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "001c712b",
        "outputId": "bcf4dbeb-c397-4af2-caf0-41304b7e4912"
      },
      "outputs": [],
      "source": [
        "# Cell: Fixed Dataset Loading with Better Subsampling\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from utils import subsample\n",
        "\n",
        "DATASET = \"cifar100\"  # @param [\"cifar100\", \"flowers102\"]\n",
        "METHOD = \"full\"       # @param [\"full\", \"lora\", \"adaptformer\", \"bitfit\"]\n",
        "\n",
        "# Dataset configurations\n",
        "dataset_configs = {\n",
        "    \"cifar100\": {\n",
        "        \"num_classes\": 100,\n",
        "        \"data_dir\": \"./data/cifar-100-python\",\n",
        "        \"mean\": [0.485, 0.456, 0.406],\n",
        "        \"std\": [0.229, 0.224, 0.225]\n",
        "    },\n",
        "    \"flowers102\": {\n",
        "        \"num_classes\": 102,\n",
        "        \"data_dir\": \"./data/flowers102\",\n",
        "        \"mean\": [0.485, 0.456, 0.406], \n",
        "        \"std\": [0.229, 0.224, 0.225]\n",
        "    }\n",
        "}\n",
        "\n",
        "config = dataset_configs[DATASET]\n",
        "\n",
        "# Transform for analysis\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(config[\"mean\"], config[\"std\"])\n",
        "])\n",
        "\n",
        "# Load dataset with proper handling\n",
        "dataset_test = None\n",
        "\n",
        "if DATASET == \"cifar100\":\n",
        "    dataset_test = datasets.CIFAR100(\n",
        "        root=config[\"data_dir\"], \n",
        "        train=False, \n",
        "        download=True, \n",
        "        transform=transform_test\n",
        "    )\n",
        "    print(f\"CIFAR-100 dataset loaded: {len(dataset_test)} images\")\n",
        "    \n",
        "elif DATASET == \"flowers102\":\n",
        "    # Use the path we know works\n",
        "    test_dir = \"./data/flowers102/dataset/valid\"\n",
        "    try:\n",
        "        dataset_test = datasets.ImageFolder(test_dir, transform=transform_test)\n",
        "        print(f\"Using {test_dir}: {len(dataset_test)} images\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {test_dir}: {e}\")\n",
        "\n",
        "# Create DataLoader if dataset was loaded successfully\n",
        "if dataset_test is not None:\n",
        "    # Better subsampling - use a larger ratio or fixed number\n",
        "    original_size = len(dataset_test)\n",
        "    \n",
        "    # For analysis, we want at least 200-500 samples\n",
        "    if original_size > 500:\n",
        "        # Use a ratio that gives us ~300 samples\n",
        "        target_samples = 300\n",
        "        subsample_ratio = target_samples / original_size\n",
        "    else:\n",
        "        # Use all samples if dataset is small\n",
        "        subsample_ratio = 1.0\n",
        "    \n",
        "    print(f\"Using subsample ratio: {subsample_ratio:.3f}\")\n",
        "    \n",
        "    if subsample_ratio < 1.0:\n",
        "        subsample_indices = subsample(dataset_test, ratio=subsample_ratio)\n",
        "        dataset_test = torch.utils.data.Subset(dataset_test, subsample_indices)\n",
        "        print(f\"Subsampled from {original_size} to {len(dataset_test)} images\")\n",
        "    else:\n",
        "        print(f\"Using all {original_size} images\")\n",
        "    \n",
        "    # Create DataLoader with smaller batch size for analysis\n",
        "    dataset_test = DataLoader(dataset_test, num_workers=0, batch_size=8, shuffle=False)\n",
        "    \n",
        "    # Test the DataLoader\n",
        "    try:\n",
        "        test_batch = next(iter(dataset_test))\n",
        "        print(f\"DataLoader working - batch shape: {test_batch[0].shape}\")\n",
        "        # Reset iterator\n",
        "        dataset_test = DataLoader(torch.utils.data.Subset(dataset_test.dataset, \n",
        "                                                         list(range(len(dataset_test.dataset)))), \n",
        "                                 num_workers=0, batch_size=8, shuffle=False)\n",
        "    except StopIteration:\n",
        "        print(\"DataLoader is empty\")\n",
        "        dataset_test = None\n",
        "    except Exception as e:\n",
        "        print(f\"DataLoader error: {e}\")\n",
        "        dataset_test = None\n",
        "else:\n",
        "    print(\"No valid dataset found\")\n",
        "    \n",
        "print(f\"Final status - Dataset: {'Ready' if dataset_test else '‚ùå None'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62f9f784",
      "metadata": {
        "id": "62f9f784"
      },
      "source": [
        "## Load the Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "286f25d7",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "286f25d7",
        "outputId": "38307a98-bf9c-411e-a7e4-6bea164b1151"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import ViTForImageClassification\n",
        "from models.lora_vit import apply_lora_to_vit\n",
        "from models.adapt_former import apply_adaptformer_to_vit  # Uncomment this\n",
        "from models.bitfit_vit import apply_bitfit_to_vit          # Uncomment this\n",
        "\n",
        "def load_finetuned_model(checkpoint_path, dataset_name, method=\"full\"):\n",
        "    \"\"\"Load a fine-tuned model from checkpoint\"\"\"\n",
        "    \n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
        "        return None\n",
        "    \n",
        "    # Get number of classes\n",
        "    num_classes_map = {\"cifar10\": 10, \"cifar100\": 100, \"flowers102\": 102}\n",
        "    num_classes = num_classes_map[dataset_name]\n",
        "    \n",
        "    try:\n",
        "        # Create base model - ADD output flags for analysis\n",
        "        model = ViTForImageClassification.from_pretrained(\n",
        "            \"facebook/dino-vits16\",\n",
        "            num_labels=num_classes,\n",
        "            ignore_mismatched_sizes=True,\n",
        "            output_attentions=True,      # Add this for attention analysis\n",
        "            output_hidden_states=True    # Add this for representation analysis\n",
        "        )\n",
        "        \n",
        "        # Apply fine-tuning method BEFORE loading checkpoint\n",
        "        if method == \"lora\":\n",
        "            apply_lora_to_vit(model, r=8, alpha=16, dropout=0.1)\n",
        "        elif method == \"bitfit\":\n",
        "            # BitFit is applied after loading\n",
        "            pass\n",
        "        elif method == \"adaptformer\":\n",
        "            apply_adaptformer_to_vit(model, bottleneck_dim=64)  # Add this\n",
        "        # elif method == \"full\": no additional setup needed\n",
        "        \n",
        "        # Load checkpoint\n",
        "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        \n",
        "        # Apply BitFit after loading (only changes requires_grad)\n",
        "        if method == \"bitfit\":\n",
        "            apply_bitfit_to_vit(model, verbose=False)\n",
        "        \n",
        "        model = model.cuda()\n",
        "        model = model.eval()\n",
        "        \n",
        "        print(f\"‚úÖ Loaded: {dataset_name}_{method}\")\n",
        "        return model\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading {checkpoint_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load all available models\n",
        "models = {}\n",
        "methods = [\"full\", \"lora\", \"bitfit\", \"adaptformer\"]\n",
        "datasets = [\"cifar100\", \"flowers102\"]\n",
        "\n",
        "print(\"üîç Testing model loading...\")\n",
        "for dataset in datasets:\n",
        "    for method in methods:\n",
        "        checkpoint_path = f\"./checkpoints/{dataset}/{method}/best_checkpoint_{dataset}_{method}.pth\"\n",
        "        model_key = f\"{dataset}_{method}\"\n",
        "        models[model_key] = load_finetuned_model(checkpoint_path, dataset, method)\n",
        "\n",
        "# Filter out None models\n",
        "available_models = {k: v for k, v in models.items() if v is not None}\n",
        "print(f\"\\nüìã Available models: {list(available_models.keys())}\")\n",
        "\n",
        "# Load the selected model for analysis\n",
        "current_model_key = f\"{DATASET}_{METHOD}\"\n",
        "if current_model_key in available_models:\n",
        "    selected_model = available_models[current_model_key]\n",
        "    print(f\"üéØ Selected for analysis: {current_model_key}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Selected model {current_model_key} not available\")\n",
        "    # Use fallback if available\n",
        "    if available_models:\n",
        "        fallback_key = list(available_models.keys())[0]\n",
        "        selected_model = available_models[fallback_key]\n",
        "        print(f\"üîÑ Using fallback: {fallback_key}\")\n",
        "    else:\n",
        "        selected_model = None\n",
        "        print(\"‚ùå No models available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d36551",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Analysis Wrapper - Enhanced with Debug Info\n",
        "def create_analysis_wrapper(model):\n",
        "    \"\"\"Wrap the fine-tuned model to match expected interface\"\"\"\n",
        "    def wrapped_forward(x):\n",
        "        print(f\"Forward pass input shape: {x.shape}\")\n",
        "        \n",
        "        # Get model outputs\n",
        "        with torch.no_grad():\n",
        "            outputs = model(pixel_values=x, output_attentions=True, output_hidden_states=True)\n",
        "        \n",
        "        # Extract what we need\n",
        "        logits = outputs.logits\n",
        "        hidden_states = outputs.hidden_states  # All layer outputs\n",
        "        attentions = outputs.attentions\n",
        "        \n",
        "        print(f\"Hidden states: {len(hidden_states) if hidden_states else 0} layers\")\n",
        "        if hidden_states:\n",
        "            for i, hs in enumerate(hidden_states):\n",
        "                if hs is not None:\n",
        "                    print(f\"   Layer {i}: {hs.shape}\")\n",
        "        \n",
        "        # Format for analysis (mimic original interface)\n",
        "        zs = list(hidden_states) if hidden_states else []\n",
        "        \n",
        "        # Handle attentions safely\n",
        "        if attentions is not None and len(attentions) > 0 and attentions[0] is not None:\n",
        "            attns = list(attentions)\n",
        "        else:\n",
        "            attns = [None] * len(zs)\n",
        "        \n",
        "        attn_fts = [None] * len(zs)\n",
        "        \n",
        "        return logits, zs, attns, attn_fts\n",
        "    \n",
        "    model.forward_analysis = wrapped_forward\n",
        "    return model\n",
        "\n",
        "# Wrap the selected model\n",
        "if selected_model is not None:\n",
        "    wrapped_model = create_analysis_wrapper(selected_model)\n",
        "    print(f\"Model wrapped for analysis: {DATASET}_{METHOD}\")\n",
        "else:\n",
        "    wrapped_model = None\n",
        "    print(\"No model available for analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2aa142b",
      "metadata": {
        "id": "d2aa142b"
      },
      "source": [
        "## Fourier Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c267ba32",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "c267ba32",
        "outputId": "f0c7f7e5-29e9-4642-f841-93f061e1ca1d"
      },
      "outputs": [],
      "source": [
        "# Cell: Fourier Analysis - Fixed with Better Error Handling\n",
        "import matplotlib.pyplot as plt\n",
        "from einops import rearrange, reduce, repeat\n",
        "from timm.utils import AverageMeter\n",
        "\n",
        "def fourier(x):\n",
        "    \"\"\"2D Fourier transform\"\"\"\n",
        "    f = torch.fft.fft2(x)\n",
        "    f = f.abs() + 1e-6\n",
        "    f = f.log()\n",
        "    return f\n",
        "\n",
        "def shift(x):  \n",
        "    \"\"\"shift Fourier transformed feature map\"\"\"\n",
        "    b, c, h, w = x.shape\n",
        "    return torch.roll(x, shifts=(int(h/2), int(w/2)), dims=(2, 3))\n",
        "\n",
        "def get_fourier_latents(latents):\n",
        "    \"\"\"Fourier transform feature maps\"\"\"\n",
        "    fourier_latents = []\n",
        "    for latent in latents:\n",
        "        latent = latent.cpu()\n",
        "        b, n, c = latent.shape\n",
        "        h, w = int(math.sqrt(n)), int(math.sqrt(n))\n",
        "        \n",
        "        if h * w != n:\n",
        "            print(f\"Non-square patch arrangement: {n} patches, expecting {h}x{w}={h*w}\")\n",
        "            continue\n",
        "            \n",
        "        latent = rearrange(latent, \"b (h w) c -> b c h w\", h=h, w=w)\n",
        "        \n",
        "        latent = fourier(latent)\n",
        "        latent = shift(latent).mean(dim=(0, 1))\n",
        "        latent = latent.diag()[int(h/2):]\n",
        "        latent = latent - latent[0]\n",
        "        fourier_latents.append(latent)\n",
        "    return fourier_latents\n",
        "\n",
        "# Run Fourier analysis with better error handling\n",
        "if wrapped_model is not None and dataset_test is not None:\n",
        "    print(f\"Running Fourier Analysis for {DATASET}_{METHOD}...\")\n",
        "    \n",
        "    fourier_latents = AverageMeter()\n",
        "    batch_count = 0\n",
        "    \n",
        "    for i, (xs, ys) in enumerate(dataset_test):\n",
        "        try:\n",
        "            print(f\"Processing batch {i+1}, input shape: {xs.shape}\")\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                xs = xs.cuda()\n",
        "                _, zs, _, _ = wrapped_model.forward_analysis(xs)\n",
        "                \n",
        "            print(f\"Got {len(zs)} layers from model\")\n",
        "            \n",
        "            # Remove final classification layer and filter valid layers\n",
        "            valid_zs = [z for z in zs[:-1] if z is not None]\n",
        "            print(f\"Valid layers: {len(valid_zs)}\")\n",
        "            \n",
        "            if valid_zs:\n",
        "                # Remove CLS token\n",
        "                latents = [z[:,1:,:] for z in valid_zs]\n",
        "                print(f\"Processing {len(latents)} latent layers\")\n",
        "                \n",
        "                _fourier_latents = get_fourier_latents(latents)\n",
        "                \n",
        "                if _fourier_latents:\n",
        "                    fourier_tensor = torch.stack(_fourier_latents)\n",
        "                    fourier_latents.update(fourier_tensor)\n",
        "                    print(f\"Updated Fourier latents: {fourier_tensor.shape}\")\n",
        "                else:\n",
        "                    print(\"No valid Fourier latents from this batch\")\n",
        "            else:\n",
        "                print(\"No valid hidden states in this batch\")\n",
        "            \n",
        "            batch_count += 1\n",
        "            if batch_count >= 3:  # Process a few batches\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch {i}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    # Plot results\n",
        "    if fourier_latents.count > 0:\n",
        "        print(f\"Plotting Fourier analysis from {fourier_latents.count} batches\")\n",
        "        \n",
        "        fig, ax = plt.subplots(1, 1, figsize=(6, 5), dpi=150)\n",
        "        fourier_avg = fourier_latents.avg\n",
        "        \n",
        "        print(f\"Fourier average shape: {fourier_avg.shape}\")\n",
        "        \n",
        "        ax.plot(range(len(fourier_avg)), fourier_avg[:,-1], marker=\"o\", linewidth=2, markersize=6)\n",
        "        ax.set_xlabel(\"Depth\", fontsize=12)\n",
        "        ax.set_ylabel(\"$\\Delta$ Log amplitude\", fontsize=12)\n",
        "        ax.set_title(f\"Fourier Analysis - {DATASET.upper()} ({METHOD.upper()})\", fontsize=14, fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_ylim(top=-1.5, bottom=-3.5)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No Fourier data collected - check model and dataset\")\n",
        "else:\n",
        "    print(\"Cannot run Fourier analysis - missing model or dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5daf240",
      "metadata": {
        "id": "c5daf240"
      },
      "source": [
        "## Toekn-level t-SNE Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ebd559",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "c0ebd559",
        "outputId": "bbcd079b-83c1-4753-c00f-95c5c1817aef"
      },
      "outputs": [],
      "source": [
        "# Cell: t-SNE Analysis - Fixed with Better Error Handling\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.manifold import TSNE\n",
        "from einops import rearrange, reduce, repeat\n",
        "\n",
        "def visualize_token_tsne(ax, zs, depth, ys, title=\"\", cmap=cm.get_cmap(\"plasma\")): \n",
        "    if depth >= len(zs) or zs[depth] is None:\n",
        "        ax.text(0.5, 0.5, \"No data available\", ha='center', va='center', transform=ax.transAxes)\n",
        "        return\n",
        "    \n",
        "    latents = zs[depth]\n",
        "    print(f\"t-SNE input shape: {latents.shape}\")\n",
        "    \n",
        "    latents = latents[:,1:,:]  # drop cls\n",
        "    latents = rearrange(latents, \"b n c -> (b n) c\")\n",
        "    latents = latents.cpu()\n",
        "    \n",
        "    print(f\"t-SNE latents shape after reshape: {latents.shape}\")\n",
        "\n",
        "    # Ensure we have enough samples for t-SNE\n",
        "    min_samples = 30\n",
        "    if latents.shape[0] < min_samples:\n",
        "        ax.text(0.5, 0.5, f\"Not enough samples for t-SNE\\n(need {min_samples}, got {latents.shape[0]})\", \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "        return\n",
        "\n",
        "    perplexity = min(20, latents.shape[0]//3)\n",
        "    reducer = TSNE(n_components=2, perplexity=perplexity, \n",
        "                   learning_rate='auto', init='random', n_iter=1000)\n",
        "    embedded = reducer.fit_transform(latents)\n",
        "    \n",
        "    labels = ys.cpu().numpy() if torch.is_tensor(ys) else ys\n",
        "    labels = np.array([[label] * (latents.shape[0]//len(labels)) for label in labels]).flatten()\n",
        "    c = [cmap(label / (max(labels) + 0.5)) for label in labels]\n",
        "    \n",
        "    ax.scatter(embedded[:,0], embedded[:,1], c=c, s=2, alpha=0.7)\n",
        "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "# Run t-SNE analysis with better error handling\n",
        "if wrapped_model is not None and dataset_test is not None:\n",
        "    print(f\"Running t-SNE Analysis for {DATASET}_{METHOD}...\")\n",
        "    \n",
        "    try:\n",
        "        # Get first batch\n",
        "        xs, ys = next(iter(dataset_test))\n",
        "        print(f\"Got batch - xs: {xs.shape}, ys: {len(ys)}\")\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            xs = xs.cuda()\n",
        "            _, zs, _, _ = wrapped_model.forward_analysis(xs)\n",
        "            zs = [z for z in zs[:-1] if z is not None]  # Remove final layer and filter None\n",
        "        \n",
        "        print(f\"Valid layers for t-SNE: {len(zs)}\")\n",
        "        \n",
        "        if zs:\n",
        "            depth = min(10, len(zs)-1)  # Use layer 10 or the last available layer\n",
        "            print(f\"Using layer {depth}\")\n",
        "            \n",
        "            fig, ax = plt.subplots(1, 1, figsize=(6, 5), dpi=150)\n",
        "            title = f\"t-SNE (Layer {depth}) - {DATASET.upper()} ({METHOD.upper()})\"\n",
        "            visualize_token_tsne(ax, zs, depth=depth, ys=ys, title=title)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No valid layers for t-SNE analysis\")\n",
        "            \n",
        "    except StopIteration:\n",
        "        print(\"Dataset is empty - no data available for t-SNE\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in t-SNE analysis: {e}\")\n",
        "else:\n",
        "    print(\"Cannot run t-SNE analysis - missing model or dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e567d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Comparative Fourier Analysis - All Models\n",
        "import matplotlib.pyplot as plt\n",
        "from einops import rearrange, reduce, repeat\n",
        "from timm.utils import AverageMeter\n",
        "import numpy as np\n",
        "\n",
        "def fourier(x):\n",
        "    \"\"\"2D Fourier transform\"\"\"\n",
        "    f = torch.fft.fft2(x)\n",
        "    f = f.abs() + 1e-6\n",
        "    f = f.log()\n",
        "    return f\n",
        "\n",
        "def shift(x):  \n",
        "    \"\"\"shift Fourier transformed feature map\"\"\"\n",
        "    b, c, h, w = x.shape\n",
        "    return torch.roll(x, shifts=(int(h/2), int(w/2)), dims=(2, 3))\n",
        "\n",
        "def get_fourier_latents(latents):\n",
        "    \"\"\"Fourier transform feature maps\"\"\"\n",
        "    fourier_latents = []\n",
        "    for latent in latents:\n",
        "        latent = latent.cpu()\n",
        "        b, n, c = latent.shape\n",
        "        h, w = int(math.sqrt(n)), int(math.sqrt(n))\n",
        "        \n",
        "        if h * w != n:\n",
        "            print(f\"Non-square patch arrangement: {n} patches, expecting {h}x{w}={h*w}\")\n",
        "            continue\n",
        "            \n",
        "        latent = rearrange(latent, \"b (h w) c -> b c h w\", h=h, w=w)\n",
        "        \n",
        "        latent = fourier(latent)\n",
        "        latent = shift(latent).mean(dim=(0, 1))\n",
        "        latent = latent.diag()[int(h/2):]\n",
        "        latent = latent - latent[0]\n",
        "        fourier_latents.append(latent)\n",
        "    return fourier_latents\n",
        "\n",
        "def analyze_model_fourier(model, dataset_loader, model_name, max_batches=3):\n",
        "    \"\"\"Analyze Fourier characteristics for a single model\"\"\"\n",
        "    print(f\"Analyzing {model_name}...\")\n",
        "    \n",
        "    fourier_latents = AverageMeter()\n",
        "    batch_count = 0\n",
        "    \n",
        "    wrapped_model = create_analysis_wrapper(model)\n",
        "    \n",
        "    for i, (xs, ys) in enumerate(dataset_loader):\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                xs = xs.cuda()\n",
        "                _, zs, _, _ = wrapped_model.forward_analysis(xs)\n",
        "                \n",
        "            # Remove final classification layer and filter valid layers\n",
        "            valid_zs = [z for z in zs[:-1] if z is not None]\n",
        "            \n",
        "            if valid_zs:\n",
        "                # Remove CLS token\n",
        "                latents = [z[:,1:,:] for z in valid_zs]\n",
        "                _fourier_latents = get_fourier_latents(latents)\n",
        "                \n",
        "                if _fourier_latents:\n",
        "                    fourier_tensor = torch.stack(_fourier_latents)\n",
        "                    fourier_latents.update(fourier_tensor)\n",
        "            \n",
        "            batch_count += 1\n",
        "            if batch_count >= max_batches:\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch {i}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if fourier_latents.count > 0:\n",
        "        print(f\"Collected data from {fourier_latents.count} batches\")\n",
        "        return fourier_latents.avg\n",
        "    else:\n",
        "        print(f\"No valid data collected\")\n",
        "        return None\n",
        "\n",
        "# Run comparative analysis if we have models and dataset\n",
        "if available_models and dataset_test is not None:\n",
        "    print(f\"üîç Running Comparative Fourier Analysis for {DATASET.upper()}...\")\n",
        "    \n",
        "    # Define visual styles for each method\n",
        "    method_styles = {\n",
        "        'full': {'marker': 'o', 'color': '#1f77b4', 'linestyle': '-', 'label': 'Full Fine-tuning'},\n",
        "        'lora': {'marker': 's', 'color': '#ff7f0e', 'linestyle': '--', 'label': 'LoRA'},\n",
        "        'bitfit': {'marker': '^', 'color': '#2ca02c', 'linestyle': '-.', 'label': 'BitFit'},\n",
        "        'adaptformer': {'marker': 'D', 'color': '#d62728', 'linestyle': ':', 'label': 'AdaptFormer'}\n",
        "    }\n",
        "    \n",
        "    # Collect results for all models\n",
        "    results = {}\n",
        "    \n",
        "    for model_key, model in available_models.items():\n",
        "        dataset_name, method = model_key.split('_')\n",
        "        \n",
        "        # Only analyze models for the current dataset\n",
        "        if dataset_name == DATASET:\n",
        "            fourier_avg = analyze_model_fourier(model, dataset_test, model_key)\n",
        "            if fourier_avg is not None:\n",
        "                results[method] = fourier_avg\n",
        "    \n",
        "    # Plot comparative results\n",
        "    if results:\n",
        "        print(f\"\\nPlotting comparative results...\")\n",
        "        \n",
        "        fig, ax = plt.subplots(1, 1, figsize=(10, 6), dpi=150)\n",
        "        \n",
        "        for method, fourier_avg in results.items():\n",
        "            style = method_styles.get(method, {'marker': 'o', 'color': 'black', 'linestyle': '-', 'label': method})\n",
        "            \n",
        "            x_values = range(len(fourier_avg))\n",
        "            y_values = fourier_avg[:, -1].cpu().numpy()\n",
        "            \n",
        "            ax.plot(x_values, y_values, \n",
        "                   marker=style['marker'], \n",
        "                   color=style['color'],\n",
        "                   linestyle=style['linestyle'],\n",
        "                   linewidth=2.5, \n",
        "                   markersize=8,\n",
        "                   markerfacecolor='white',\n",
        "                   markeredgecolor=style['color'],\n",
        "                   markeredgewidth=2,\n",
        "                   label=style['label'],\n",
        "                   alpha=0.8)\n",
        "        \n",
        "        # Customize the plot\n",
        "        ax.set_xlabel(\"Layer Depth\", fontsize=14, fontweight='bold')\n",
        "        ax.set_ylabel(\"Œî Log Amplitude\", fontsize=14, fontweight='bold')\n",
        "        ax.set_title(f\"Fourier Analysis Comparison - {DATASET.upper()}\", \n",
        "                    fontsize=16, fontweight='bold', pad=20)\n",
        "        \n",
        "        # Add grid and legend\n",
        "        ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
        "        ax.legend(fontsize=12, frameon=True, fancybox=True, shadow=True, \n",
        "                 bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        \n",
        "        # Set axis limits and styling\n",
        "        ax.set_ylim(top=-1.5, bottom=-3.5)\n",
        "        ax.tick_params(axis='both', which='major', labelsize=11)\n",
        "        \n",
        "        # Add subtle background\n",
        "        ax.set_facecolor('#fafafa')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print summary statistics\n",
        "        print(\"\\nSummary Statistics:\")\n",
        "        print(\"=\" * 50)\n",
        "        for method, fourier_avg in results.items():\n",
        "            final_values = fourier_avg[:, -1].cpu().numpy()\n",
        "            print(f\"{method_styles[method]['label']:15} | \"\n",
        "                  f\"Mean: {final_values.mean():.3f} | \"\n",
        "                  f\"Std: {final_values.std():.3f} | \"\n",
        "                  f\"Min: {final_values.min():.3f} | \"\n",
        "                  f\"Max: {final_values.max():.3f}\")\n",
        "        \n",
        "    else:\n",
        "        print(\"No valid results collected for comparison\")\n",
        "        \n",
        "else:\n",
        "    print(\"Cannot run comparative analysis - missing models or dataset\")\n",
        "    print(f\"Available models: {list(available_models.keys()) if available_models else 'None'}\")\n",
        "    print(f\"Dataset available: {dataset_test is not None}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "vitlora",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
