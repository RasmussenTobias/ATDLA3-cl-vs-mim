[
  {
    "epoch": 1,
    "train_loss": 5.9188232440574495,
    "train_acc": 0.00784313725490196,
    "val_loss": 5.314048464158002,
    "val_acc": 0.00980392156862745,
    "learning_rate": 5e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 2,
    "train_loss": 5.079033399095723,
    "train_acc": 0.01764705882352941,
    "val_loss": 4.7058621088663735,
    "val_acc": 0.03627450980392157,
    "learning_rate": 4.998766400914329e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 3,
    "train_loss": 4.547213621700512,
    "train_acc": 0.0392156862745098,
    "val_loss": 4.239805161719229,
    "val_acc": 0.07352941176470588,
    "learning_rate": 4.995066821070679e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 4,
    "train_loss": 4.106768560409546,
    "train_acc": 0.10196078431372549,
    "val_loss": 3.832796173469693,
    "val_acc": 0.1411764705882353,
    "learning_rate": 4.9889049115077005e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 5,
    "train_loss": 3.6428795066534305,
    "train_acc": 0.17647058823529413,
    "val_loss": 3.441780623267679,
    "val_acc": 0.23431372549019608,
    "learning_rate": 4.9802867532861956e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 6,
    "train_loss": 3.254863738078697,
    "train_acc": 0.2529411764705882,
    "val_loss": 3.047078271005668,
    "val_acc": 0.31862745098039214,
    "learning_rate": 4.969220851487845e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 7,
    "train_loss": 2.8226857811796897,
    "train_acc": 0.3862745098039216,
    "val_loss": 2.6293409272736192,
    "val_acc": 0.40980392156862744,
    "learning_rate": 4.9557181268217227e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 8,
    "train_loss": 2.381610041038663,
    "train_acc": 0.49019607843137253,
    "val_loss": 2.2464822217529896,
    "val_acc": 0.49411764705882355,
    "learning_rate": 4.939791904846869e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 9,
    "train_loss": 1.9640191910313625,
    "train_acc": 0.596078431372549,
    "val_loss": 1.8939880824556539,
    "val_acc": 0.5813725490196079,
    "learning_rate": 4.921457902821578e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 10,
    "train_loss": 1.6164807361714981,
    "train_acc": 0.692156862745098,
    "val_loss": 1.6066164278516581,
    "val_acc": 0.6470588235294118,
    "learning_rate": 4.9007342141923585e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 11,
    "train_loss": 1.336624099226559,
    "train_acc": 0.7284313725490196,
    "val_loss": 1.373093444225835,
    "val_acc": 0.7009803921568627,
    "learning_rate": 4.877641290737885e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 12,
    "train_loss": 1.1342224387561575,
    "train_acc": 0.788235294117647,
    "val_loss": 1.2051330832874074,
    "val_acc": 0.734313725490196,
    "learning_rate": 4.852201922385565e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 13,
    "train_loss": 0.9658972412932153,
    "train_acc": 0.8196078431372549,
    "val_loss": 1.0877345234740015,
    "val_acc": 0.7529411764705882,
    "learning_rate": 4.82444121472063e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 14,
    "train_loss": 0.8043287473566392,
    "train_acc": 0.8607843137254902,
    "val_loss": 0.9923968974281759,
    "val_acc": 0.7735294117647059,
    "learning_rate": 4.794386564209954e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 15,
    "train_loss": 0.7065125640700846,
    "train_acc": 0.8754901960784314,
    "val_loss": 0.8872679941794451,
    "val_acc": 0.8058823529411765,
    "learning_rate": 4.76206763116505e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 16,
    "train_loss": 0.5656486539279714,
    "train_acc": 0.8970588235294118,
    "val_loss": 0.8172365349881789,
    "val_acc": 0.8019607843137255,
    "learning_rate": 4.727516310470921e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 17,
    "train_loss": 0.5627019304855198,
    "train_acc": 0.8950980392156863,
    "val_loss": 0.7591703643985823,
    "val_acc": 0.8176470588235294,
    "learning_rate": 4.6907667001096604e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 18,
    "train_loss": 0.4602128316374386,
    "train_acc": 0.9245098039215687,
    "val_loss": 0.7205721897237441,
    "val_acc": 0.8343137254901961,
    "learning_rate": 4.651855067509861e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 19,
    "train_loss": 0.4509248206428453,
    "train_acc": 0.9254901960784314,
    "val_loss": 0.6909106607530632,
    "val_acc": 0.842156862745098,
    "learning_rate": 4.61081981375504e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 20,
    "train_loss": 0.4393727335275388,
    "train_acc": 0.9343137254901961,
    "val_loss": 0.6490526989394543,
    "val_acc": 0.8441176470588235,
    "learning_rate": 4.567701435686407e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 21,
    "train_loss": 0.3223312824380164,
    "train_acc": 0.9549019607843138,
    "val_loss": 0.6209475017061421,
    "val_acc": 0.8539215686274509,
    "learning_rate": 4.522542485937371e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 22,
    "train_loss": 0.33499593471779543,
    "train_acc": 0.9470588235294117,
    "val_loss": 0.599892305392845,
    "val_acc": 0.8568627450980392,
    "learning_rate": 4.475387530939228e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 23,
    "train_loss": 0.33701871680278406,
    "train_acc": 0.946078431372549,
    "val_loss": 0.5845307068497527,
    "val_acc": 0.8588235294117647,
    "learning_rate": 4.426283106939475e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 24,
    "train_loss": 0.29234440285785523,
    "train_acc": 0.9588235294117647,
    "val_loss": 0.5804183254054949,
    "val_acc": 0.8637254901960785,
    "learning_rate": 4.375277674076151e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 25,
    "train_loss": 0.3206957808896607,
    "train_acc": 0.9401960784313725,
    "val_loss": 0.5363985114237841,
    "val_acc": 0.8725490196078431,
    "learning_rate": 4.322421568553531e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 26,
    "train_loss": 0.2947957332227744,
    "train_acc": 0.9529411764705882,
    "val_loss": 0.5501384340080561,
    "val_acc": 0.8607843137254902,
    "learning_rate": 4.26776695296637e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 27,
    "train_loss": 0.23717868152786703,
    "train_acc": 0.9666666666666667,
    "val_loss": 0.5214543475824244,
    "val_acc": 0.8745098039215686,
    "learning_rate": 4.211367764821723e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 28,
    "train_loss": 0.3015473292154424,
    "train_acc": 0.9509803921568627,
    "val_loss": 0.5241628177025739,
    "val_acc": 0.8754901960784314,
    "learning_rate": 4.153279663309131e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 29,
    "train_loss": 0.25550112338627085,
    "train_acc": 0.9598039215686275,
    "val_loss": 0.49287791287197785,
    "val_acc": 0.8823529411764706,
    "learning_rate": 4.0935599743717254e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 30,
    "train_loss": 0.213844097478717,
    "train_acc": 0.9686274509803922,
    "val_loss": 0.4913017284636404,
    "val_acc": 0.888235294117647,
    "learning_rate": 4.032267634132443e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 31,
    "train_loss": 0.21159459069079045,
    "train_acc": 0.9656862745098039,
    "val_loss": 0.4822381214768279,
    "val_acc": 0.8852941176470588,
    "learning_rate": 3.969463130731185e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 32,
    "train_loss": 0.20465364760043575,
    "train_acc": 0.9666666666666667,
    "val_loss": 0.47025190416504353,
    "val_acc": 0.8901960784313725,
    "learning_rate": 3.905208444630329e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 33,
    "train_loss": 0.21535126578574088,
    "train_acc": 0.9627450980392157,
    "val_loss": 0.47527218309103275,
    "val_acc": 0.8862745098039215,
    "learning_rate": 3.8395669874474935e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 34,
    "train_loss": 0.19998844102317212,
    "train_acc": 0.9686274509803922,
    "val_loss": 0.4706121721688439,
    "val_acc": 0.8872549019607843,
    "learning_rate": 3.7726035393759305e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 35,
    "train_loss": 0.15908341904481252,
    "train_acc": 0.9754901960784313,
    "val_loss": 0.46376787342277226,
    "val_acc": 0.8862745098039215,
    "learning_rate": 3.70438418525429e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 36,
    "train_loss": 0.19937203964766334,
    "train_acc": 0.9666666666666667,
    "val_loss": 0.4406847559938244,
    "val_acc": 0.8941176470588236,
    "learning_rate": 3.634976249348869e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 37,
    "train_loss": 0.2026167825156567,
    "train_acc": 0.961764705882353,
    "val_loss": 0.46345072026346246,
    "val_acc": 0.8852941176470588,
    "learning_rate": 3.564448228912684e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 38,
    "train_loss": 0.18049465552264568,
    "train_acc": 0.9686274509803922,
    "val_loss": 0.4420866464867311,
    "val_acc": 0.8931372549019608,
    "learning_rate": 3.4928697265869536e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 39,
    "train_loss": 0.21882138182135188,
    "train_acc": 0.957843137254902,
    "val_loss": 0.4310502045294818,
    "val_acc": 0.8990196078431373,
    "learning_rate": 3.420311381711698e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 40,
    "train_loss": 0.20414570824188344,
    "train_acc": 0.9637254901960784,
    "val_loss": 0.4416053980004554,
    "val_acc": 0.8852941176470588,
    "learning_rate": 3.346844800613231e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 41,
    "train_loss": 0.17531811971874797,
    "train_acc": 0.9725490196078431,
    "val_loss": 0.42898015122787625,
    "val_acc": 0.8794117647058823,
    "learning_rate": 3.272542485937371e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 42,
    "train_loss": 0.15246138157797795,
    "train_acc": 0.9656862745098039,
    "val_loss": 0.41764546983382284,
    "val_acc": 0.8950980392156863,
    "learning_rate": 3.197477765098076e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 43,
    "train_loss": 0.13660539981781267,
    "train_acc": 0.9803921568627451,
    "val_loss": 0.41757499762609895,
    "val_acc": 0.8911764705882353,
    "learning_rate": 3.121724717912139e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 44,
    "train_loss": 0.16855196724919713,
    "train_acc": 0.9656862745098039,
    "val_loss": 0.41581084856800005,
    "val_acc": 0.8862745098039215,
    "learning_rate": 3.045358103491359e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 45,
    "train_loss": 0.15553241629226536,
    "train_acc": 0.9715686274509804,
    "val_loss": 0.42443792329115027,
    "val_acc": 0.8921568627450981,
    "learning_rate": 2.9684532864643143e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 46,
    "train_loss": 0.1340659548254574,
    "train_acc": 0.9803921568627451,
    "val_loss": 0.4128399761868458,
    "val_acc": 0.9009803921568628,
    "learning_rate": 2.8910861626005796e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 47,
    "train_loss": 0.13891938001501794,
    "train_acc": 0.9764705882352941,
    "val_loss": 0.4041966758522333,
    "val_acc": 0.8990196078431373,
    "learning_rate": 2.8133330839107635e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 48,
    "train_loss": 0.1427751257723453,
    "train_acc": 0.9735294117647059,
    "val_loss": 0.40593638852530833,
    "val_acc": 0.8960784313725491,
    "learning_rate": 2.735270783296288e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 49,
    "train_loss": 0.1269103676665063,
    "train_acc": 0.9764705882352941,
    "val_loss": 0.40546243412821903,
    "val_acc": 0.9,
    "learning_rate": 2.656976298823286e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 50,
    "train_loss": 0.1348599042962579,
    "train_acc": 0.9813725490196078,
    "val_loss": 0.39653233032600554,
    "val_acc": 0.8980392156862745,
    "learning_rate": 2.578526897695323e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 51,
    "train_loss": 0.1655539824974303,
    "train_acc": 0.9735294117647059,
    "val_loss": 0.39452342601383433,
    "val_acc": 0.9049019607843137,
    "learning_rate": 2.500000000000002e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 52,
    "train_loss": 0.12846295433301552,
    "train_acc": 0.9774509803921568,
    "val_loss": 0.39143432437204845,
    "val_acc": 0.8970588235294118,
    "learning_rate": 2.4214731023046813e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 53,
    "train_loss": 0.11776074746660158,
    "train_acc": 0.9784313725490196,
    "val_loss": 0.3863064529264674,
    "val_acc": 0.8980392156862745,
    "learning_rate": 2.3430237011767184e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 54,
    "train_loss": 0.1220232672551099,
    "train_acc": 0.9764705882352941,
    "val_loss": 0.38828058570039037,
    "val_acc": 0.9,
    "learning_rate": 2.2647292167037158e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 55,
    "train_loss": 0.12286929172628067,
    "train_acc": 0.9833333333333333,
    "val_loss": 0.38189357004913627,
    "val_acc": 0.8980392156862745,
    "learning_rate": 2.186666916089241e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 56,
    "train_loss": 0.1474411929501038,
    "train_acc": 0.9794117647058823,
    "val_loss": 0.39157032510813544,
    "val_acc": 0.9009803921568628,
    "learning_rate": 2.1089138373994243e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 57,
    "train_loss": 0.10547491084126866,
    "train_acc": 0.9882352941176471,
    "val_loss": 0.3815798427544388,
    "val_acc": 0.903921568627451,
    "learning_rate": 2.03154671353569e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 58,
    "train_loss": 0.12214979865387374,
    "train_acc": 0.9794117647058823,
    "val_loss": 0.39141498628784627,
    "val_acc": 0.9009803921568628,
    "learning_rate": 1.954641896508646e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 59,
    "train_loss": 0.1263449712711222,
    "train_acc": 0.9754901960784313,
    "val_loss": 0.38493405685705295,
    "val_acc": 0.903921568627451,
    "learning_rate": 1.8782752820878645e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 60,
    "train_loss": 0.12343345798698126,
    "train_acc": 0.9803921568627451,
    "val_loss": 0.37726119610608794,
    "val_acc": 0.9019607843137255,
    "learning_rate": 1.8025222349019287e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 61,
    "train_loss": 0.0961561116371669,
    "train_acc": 0.9901960784313726,
    "val_loss": 0.3757377546791937,
    "val_acc": 0.9058823529411765,
    "learning_rate": 1.7274575140626338e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 62,
    "train_loss": 0.12024110979309269,
    "train_acc": 0.9813725490196078,
    "val_loss": 0.36802690157703327,
    "val_acc": 0.903921568627451,
    "learning_rate": 1.6531551993867734e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 63,
    "train_loss": 0.11771310947689356,
    "train_acc": 0.9823529411764705,
    "val_loss": 0.37144146041542875,
    "val_acc": 0.903921568627451,
    "learning_rate": 1.5796886182883076e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 64,
    "train_loss": 0.13362869480076958,
    "train_acc": 0.9794117647058823,
    "val_loss": 0.37159176188356735,
    "val_acc": 0.9049019607843137,
    "learning_rate": 1.5071302734130499e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 65,
    "train_loss": 0.11071011237069672,
    "train_acc": 0.9813725490196078,
    "val_loss": 0.3691187906499003,
    "val_acc": 0.9058823529411765,
    "learning_rate": 1.4355517710873199e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 66,
    "train_loss": 0.11879146765260136,
    "train_acc": 0.9774509803921568,
    "val_loss": 0.3692047711680917,
    "val_acc": 0.9029411764705882,
    "learning_rate": 1.3650237506511347e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 67,
    "train_loss": 0.13200921463031395,
    "train_acc": 0.9725490196078431,
    "val_loss": 0.3674100154755162,
    "val_acc": 0.9,
    "learning_rate": 1.295615814745713e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 68,
    "train_loss": 0.11375743483795839,
    "train_acc": 0.9803921568627451,
    "val_loss": 0.36327320606100794,
    "val_acc": 0.9029411764705882,
    "learning_rate": 1.2273964606240731e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 69,
    "train_loss": 0.09361371471017015,
    "train_acc": 0.9833333333333333,
    "val_loss": 0.3628604927483727,
    "val_acc": 0.9,
    "learning_rate": 1.1604330125525093e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 70,
    "train_loss": 0.09140013511858734,
    "train_acc": 0.9833333333333333,
    "val_loss": 0.3710486295176487,
    "val_acc": 0.9029411764705882,
    "learning_rate": 1.0947915553696747e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 71,
    "train_loss": 0.10402690522810992,
    "train_acc": 0.9852941176470589,
    "val_loss": 0.3662953044853958,
    "val_acc": 0.9068627450980392,
    "learning_rate": 1.0305368692688188e-05,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 72,
    "train_loss": 0.10392096957155303,
    "train_acc": 0.9803921568627451,
    "val_loss": 0.3639013964755862,
    "val_acc": 0.9068627450980392,
    "learning_rate": 9.677323658675597e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 73,
    "train_loss": 0.10289237353147244,
    "train_acc": 0.9813725490196078,
    "val_loss": 0.36720552397709266,
    "val_acc": 0.907843137254902,
    "learning_rate": 9.064400256282768e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 74,
    "train_loss": 0.11980594735519559,
    "train_acc": 0.9764705882352941,
    "val_loss": 0.3704641415792353,
    "val_acc": 0.9058823529411765,
    "learning_rate": 8.467203366908719e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 75,
    "train_loss": 0.1255600074342653,
    "train_acc": 0.9764705882352941,
    "val_loss": 0.3640462064275555,
    "val_acc": 0.9088235294117647,
    "learning_rate": 7.886322351782793e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 76,
    "train_loss": 0.08964943859507056,
    "train_acc": 0.9882352941176471,
    "val_loss": 0.36120683591739805,
    "val_acc": 0.907843137254902,
    "learning_rate": 7.322330470336324e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 77,
    "train_loss": 0.09797499632718516,
    "train_acc": 0.9803921568627451,
    "val_loss": 0.36120824942401814,
    "val_acc": 0.907843137254902,
    "learning_rate": 6.775784314464726e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 78,
    "train_loss": 0.11841109026880825,
    "train_acc": 0.9735294117647059,
    "val_loss": 0.3650673976715873,
    "val_acc": 0.9049019607843137,
    "learning_rate": 6.247223259238518e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 79,
    "train_loss": 0.10252703860694287,
    "train_acc": 0.984313725490196,
    "val_loss": 0.36484247574619216,
    "val_acc": 0.907843137254902,
    "learning_rate": 5.737168930605279e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 80,
    "train_loss": 0.09100981559239182,
    "train_acc": 0.9862745098039216,
    "val_loss": 0.36287030951649535,
    "val_acc": 0.9098039215686274,
    "learning_rate": 5.246124690607747e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": true
  },
  {
    "epoch": 81,
    "train_loss": 0.11003386173762528,
    "train_acc": 0.9813725490196078,
    "val_loss": 0.3609774784714568,
    "val_acc": 0.907843137254902,
    "learning_rate": 4.774575140626323e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 82,
    "train_loss": 0.0819327645442065,
    "train_acc": 0.9882352941176471,
    "val_loss": 0.3590192321468802,
    "val_acc": 0.9088235294117647,
    "learning_rate": 4.322985643135963e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 83,
    "train_loss": 0.11985942617643114,
    "train_acc": 0.9794117647058823,
    "val_loss": 0.3572831411572064,
    "val_acc": 0.9088235294117647,
    "learning_rate": 3.891801862449634e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 84,
    "train_loss": 0.09504759767476251,
    "train_acc": 0.9862745098039216,
    "val_loss": 0.3585281277404112,
    "val_acc": 0.9068627450980392,
    "learning_rate": 3.4814493249014108e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 85,
    "train_loss": 0.08363304512173522,
    "train_acc": 0.9852941176470589,
    "val_loss": 0.35637359087373693,
    "val_acc": 0.9098039215686274,
    "learning_rate": 3.0923329989034145e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 86,
    "train_loss": 0.1128716376190092,
    "train_acc": 0.9754901960784313,
    "val_loss": 0.353237118323644,
    "val_acc": 0.9098039215686274,
    "learning_rate": 2.7248368952908087e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 87,
    "train_loss": 0.08879485130310058,
    "train_acc": 0.9872549019607844,
    "val_loss": 0.3534619697753121,
    "val_acc": 0.9098039215686274,
    "learning_rate": 2.379323688349519e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 88,
    "train_loss": 0.1166143680758336,
    "train_acc": 0.9803921568627451,
    "val_loss": 0.35342946315512935,
    "val_acc": 0.9098039215686274,
    "learning_rate": 2.0561343579004796e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 89,
    "train_loss": 0.07953917647109313,
    "train_acc": 0.9852941176470589,
    "val_loss": 0.3531873053779789,
    "val_acc": 0.9088235294117647,
    "learning_rate": 1.7555878527937183e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  },
  {
    "epoch": 90,
    "train_loss": 0.10343974536540461,
    "train_acc": 0.9823529411764705,
    "val_loss": 0.3534342866902258,
    "val_acc": 0.9068627450980392,
    "learning_rate": 1.4779807761443653e-06,
    "dataset": "flowers102",
    "method": "lora",
    "is_best": false
  }
]